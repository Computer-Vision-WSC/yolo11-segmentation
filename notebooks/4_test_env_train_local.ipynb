{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.- Test Environment Train Local\n",
    "\n",
    "## Sanity-check fine-tuning – YOLO 11 segmentation  \n",
    "\n",
    "In this section we run a **very short local fine-tuning (1 epoch, small batch)** to confirm that the\n",
    "Docker environment, dataset paths and CPU/GPU bindings all work **before pushing the full job to Azure**.\n",
    "\n",
    "> **Prerequisites**  \n",
    "> | OS | Requirement | Notes |  \n",
    "> |----|-------------|-------|  \n",
    "> | **Windows 10/11** | Docker Desktop running | Enable “Use WSL 2 based engine” for best performance. |  \n",
    "> | **Linux** (Ubuntu, Fedora, …) | Docker Engine ≥ 20.10 | Add your user to the `docker` group or prefix commands with `sudo`. |  \n",
    "> | **macOS** | Docker Desktop **or** Colima | On Apple Silicon, be sure the image is built for `arm64`. |  \n",
    "\n",
    "All Ultralytics and PyTorch dependencies live **inside** the Docker image, keeping your host Python environment untouched.\n",
    "\n",
    "Workflow:\n",
    "\n",
    "1. **Mount volumes**  \n",
    "   * `/data/raw` – the dataset folder that contains `images/` and `data.yaml`.  \n",
    "   * `/train`  – output directory for checkpoints and run artefacts.  \n",
    "2. **Run `yolo segment train …`** with a minimal configuration:  \n",
    "   * `epochs=1`, `batch=2` — quick smoke test only.  \n",
    "   * `device=cpu` — safe default; switch to `device=0` to use your first GPU.  \n",
    "3. **Stream logs** in real time so you can verify that the training loop runs without errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Initialise the Docker client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Docker client\n",
    "client = docker.from_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Image & volumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docker image name\n",
    "docker_image = 'yolo11-docker:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_local_train_path = os.path.abspath('../data/raw')\n",
    "local_train_path = os.path.abspath('../train')\n",
    "\n",
    "# Map host paths → container paths\n",
    "\n",
    "volumes = {\n",
    "    data_local_train_path : {'bind' : '/data/raw', 'mode' : 'rw'},\n",
    "    local_train_path  : {'bind' : '/train', 'mode' : 'rw'},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) YOLO command (note the CLI uses key=value syntax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ['yolo', 'segment', 'train',\n",
    "           'data= \"/data/raw/data.yaml\"',\n",
    "           'model= \"/train/pretrained_models/yolo11x-seg.pt\"',\n",
    "           'epochs=1',\n",
    "           'batch=2',\n",
    "           'project=\"train\"',\n",
    "           'name=\"output\"',\n",
    "           'exist_ok=True',\n",
    "           'device=\"cpu\"'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Run the container and stream logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the container and capture the output\n",
    "try:\n",
    "    container = client.containers.run(\n",
    "        docker_image,         # Docker image name\n",
    "        command,              # Command to execute in container\n",
    "        volumes=volumes,      # Volumes to mount\n",
    "        detach=True,          # Run in background (detach mode)\n",
    "        stdout=True,          # Enable stdout capture\n",
    "        stderr=True,          # Enable stderr capture\n",
    "        tty=False             # Disable TTY, since we don’t need interactivity\n",
    "    )\n",
    "\n",
    "    print(\"Container is running...\")\n",
    "\n",
    "    # Collect and print logs in real-time\n",
    "    for log in container.logs(stream=True):\n",
    "        print(log.decode('utf-8'), end='')\n",
    "\n",
    "    # Wait for the container to finish\n",
    "    container.wait()\n",
    "\n",
    "    print(\"Command executed successfully\")\n",
    "\n",
    "except docker.errors.DockerException as e:\n",
    "    print(f\"Error executing Docker command: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After the run\n",
    "\n",
    "* Checkpoints (`*.pt`) and a `results.csv` with per-epoch metrics are saved under  \n",
    "  `../train/train/output/` by default.  \n",
    "* Once the smoke test passes, increase `epochs`, `batch`, or add hyper-parameters like `lr0`, `imgsz`, etc.  \n",
    "* Push the working setup to **Azure ML** (or any cloud) by re-using the same Docker\n",
    "  image and mounting your blob storage as `/data/raw`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo11-segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
