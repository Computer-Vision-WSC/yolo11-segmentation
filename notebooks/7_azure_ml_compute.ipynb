{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c53814",
   "metadata": {},
   "source": [
    "# 7.- Azure ML Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffabbfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "from azure.ai.ml.entities import AmlCompute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ddb17",
   "metadata": {},
   "source": [
    "## Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "153db1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from the YAML file\n",
    "with open(\"../config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "089d276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = config[\"azure\"][\"subscription_id\"]\n",
    "resource_group_name = config[\"azure\"][\"resource_group_name\"]\n",
    "workspace_name = config[\"azure\"][\"workspace_name\"]\n",
    "\n",
    "training_gpu_cluster = config[\"azure\"][\"training_gpu_cluster\"]\n",
    "compute_name = config[\"azure\"][\"compute_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32684ec2",
   "metadata": {},
   "source": [
    "## Azure Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "385dcef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DefaultAzureCredential\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aae8ad7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current LoggerProvider is not allowed\n",
      "Overriding of current MeterProvider is not allowed\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n"
     ]
    }
   ],
   "source": [
    "# Update Azure ML Client\n",
    "ml_client = MLClient(credential, subscription_id, resource_group_name, workspace_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b1eb73",
   "metadata": {},
   "source": [
    "## Create a Compute Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24c635ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_compute_resource(ml_client, cluster_name, size=\"STANDARD_D2_V3\", \n",
    "                            min_instances=0, max_instances=4, \n",
    "                            idle_time_before_scale_down=180, tier=\"Dedicated\"):\n",
    "    \"\"\"\n",
    "    Creates or reuses an AMLCompute resource in Azure ML.\n",
    "\n",
    "    Parameters:\n",
    "        ml_client (MLClient): The Azure ML client.\n",
    "        cluster_name (str): The name of the compute cluster.\n",
    "        size (str): The VM size (default is \"STANDARD_D2_V3\").\n",
    "        min_instances (int): The minimum number of instances (default is 0).\n",
    "        max_instances (int): The maximum number of instances (default is 4).\n",
    "        idle_time_before_scale_down (int): Idle time in seconds before scaling down (default is 180).\n",
    "        tier (str): The pricing tier, either \"Dedicated\" or \"LowPriority\" (default is \"Dedicated\").\n",
    "\n",
    "    Returns:\n",
    "        An instance of AmlCompute representing the compute resource.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the compute cluster already exists\n",
    "        compute_resource = ml_client.compute.get(cluster_name)\n",
    "        print(f\"A cluster named '{cluster_name}' already exists; reusing it.\")\n",
    "    except Exception:\n",
    "        print(\"Creating a new GPU compute resource...\")\n",
    "        compute_resource = AmlCompute(\n",
    "            name=cluster_name,\n",
    "            type=\"amlcompute\",\n",
    "            size=size,\n",
    "            min_instances=min_instances,\n",
    "            max_instances=max_instances,\n",
    "            idle_time_before_scale_down=idle_time_before_scale_down,\n",
    "            tier=tier,\n",
    "        )\n",
    "        # Create the compute resource and wait until the operation completes\n",
    "        compute_resource = ml_client.begin_create_or_update(compute_resource).result()\n",
    "    \n",
    "    print(f\"AMLCompute resource '{compute_resource.name}' is created with size '{compute_resource.size}'.\")\n",
    "    return compute_resource\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4197ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_compute_resource(ml_client, \n",
    "                        training_gpu_cluster,\n",
    "                        compute_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo11-segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
